resources:
  jobs:
    # Universal data sync workflow
    universal-data-sync:
      name: Universal Data Sync - ${var.v_team_name}
      
      tasks:
        # Example task - Oracle to Databricks
        # Copy this pattern for each pipeline you create
        - task_key: lalcl_dsg_intraday_distro_header
          notebook_task:
            notebook_path: ../src/universal_sync.py
            base_parameters:
              pipeline_id: lalcl_dsg_intraday_distro_header  # Must match pipeline_id in config/pipelines.yml
              env: ${var.v_env}
              workspace_path: ${var.v_workspace_path}
            source: WORKSPACE
          libraries:
            - maven:
                coordinates: com.oracle.ojdbc:ojdbc8:19.3.0.0  # For Oracle
                # For Azure SQL, use: com.microsoft.sqlserver:mssql-jdbc:12.2.0.jre11
          job_cluster_key: job_cluster
        
        # Oracle LALCL - Detail table (runs after header completes)
        - task_key: lalcl_dsg_intraday_distro_detail
          depends_on:
            - task_key: lalcl_dsg_intraday_distro_header
          notebook_task:
            notebook_path: ../src/universal_sync.py
            base_parameters:
              pipeline_id: lalcl_dsg_intraday_distro_detail
              env: ${var.v_env}
              workspace_path: ${var.v_workspace_path}
            source: WORKSPACE
          libraries:
            - maven:
                coordinates: com.oracle.ojdbc:ojdbc8:19.3.0.0
          job_cluster_key: job_cluster
        
        # ONE-TIME: Load FACT HEADER from Oracle (disable after first run)
        - task_key: lalcl_dsg_distro_fact_header_initial
          notebook_task:
            notebook_path: ../src/universal_sync.py
            base_parameters:
              pipeline_id: lalcl_dsg_distro_fact_header_initial
              env: ${var.v_env}
              workspace_path: ${var.v_workspace_path}
            source: WORKSPACE
          libraries:
            - maven:
                coordinates: com.oracle.ojdbc:ojdbc8:19.3.0.0
          job_cluster_key: job_cluster
        
        # ONE-TIME: Load FACT DETAIL from Oracle (disable after first run)
        - task_key: lalcl_dsg_distro_fact_detail_initial
          depends_on:
            - task_key: lalcl_dsg_distro_fact_header_initial
          notebook_task:
            notebook_path: ../src/universal_sync.py
            base_parameters:
              pipeline_id: lalcl_dsg_distro_fact_detail_initial
              env: ${var.v_env}
              workspace_path: ${var.v_workspace_path}
            source: WORKSPACE
          libraries:
            - maven:
                coordinates: com.oracle.ojdbc:ojdbc8:19.3.0.0
          job_cluster_key: job_cluster
        
        # DAILY: Merge INTRADAY to FACT HEADER (runs after intraday detail completes)
        - task_key: merge_intraday_to_fact_header
          depends_on:
            - task_key: lalcl_dsg_intraday_distro_detail
          notebook_task:
            notebook_path: ../src/universal_sync.py
            base_parameters:
              pipeline_id: merge_intraday_to_fact_header
              env: ${var.v_env}
              workspace_path: ${var.v_workspace_path}
            source: WORKSPACE
          job_cluster_key: job_cluster
        
        # DAILY: Merge INTRADAY to FACT DETAIL (runs after fact header merge completes)
        - task_key: merge_intraday_to_fact_detail
          depends_on:
            - task_key: merge_intraday_to_fact_header
          notebook_task:
            notebook_path: ../src/universal_sync.py
            base_parameters:
              pipeline_id: merge_intraday_to_fact_detail
              env: ${var.v_env}
              workspace_path: ${var.v_workspace_path}
            source: WORKSPACE
          job_cluster_key: job_cluster
        
        # Add more tasks here by copying the pattern above
        # Just change task_key and pipeline_id to match your pipelines
        
      job_clusters:
        - job_cluster_key: job_cluster
          new_cluster:
            spark_version: ${var.v_spark_version}
            node_type_id: ${var.v_node_type_id}
            custom_tags:
              TEAM_CODE: ${var.v_team_name}
            policy_id: ${var.v_job_cluster_policy_id}
            apply_policy_default_values: true
            data_security_mode: SINGLE_USER
            runtime_engine: STANDARD
            autoscale:
              min_workers: 1
              max_workers: 4
      
      # Optional: Schedule the job
      # Uncomment and customize as needed
      # schedule:
      #   quartz_cron_expression: "0 0 2 * * ?"  # Daily at 2 AM
      #   timezone_id: "America/Chicago"
      #   pause_status: UNPAUSED
